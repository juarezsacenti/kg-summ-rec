{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8t2Qabg58MwS"
   },
   "source": [
    "**Análise Exploratório de Dados - Movielens 1M**\n",
    "\n",
    "---\n",
    "\n",
    "Neste Notebook você irá analisar o dataset Movilens 1M por meio de uma análise exploratória de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NI1cVi_NGUOO"
   },
   "source": [
    "# Index\n",
    "\n",
    "1. Configuração Inicial;\n",
    "\n",
    "2. Enquadrar o problema;\n",
    "\n",
    "3. Análise Exploratória de Dados; // Qualidade dos dados, artigo performance similar em modelos distintos, qualidades dos dados tinha maior impacto. Problema de SmallData.\n",
    "    \n",
    "    3.1. ML1M;\n",
    "        3.1.1 Obter os dados;\n",
    "        3.1.2. Variáveis núméricas;\n",
    "        3.1.3. Variáveis categóricas;\n",
    "        3.1.4. Cleanning data;\n",
    "        3.1.5. Data visualization;\n",
    "       \n",
    "    3.2. ml1m-cao;\n",
    "    \n",
    "    3.3. ml1m-sun;\n",
    "    \n",
    "4. Conjuntos de treinamento / correlação / featuring engineering;\n",
    "\n",
    "5. Preparar os dados para os algoritmos;\n",
    "\n",
    "6. Selecionar e treinar modelos; // Esta e demais etapas sao realizadas pelo projeto know-rec.\n",
    "\n",
    "7. Ajustar o modelo;\n",
    "\n",
    "8. Apresentar sua solução;\n",
    "\n",
    "9. Lançar, monitorar e manter seu sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6T9pPKu28Mwe"
   },
   "source": [
    "# 1. Configuração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDJOKH5NA1QG"
   },
   "outputs": [],
   "source": [
    "# Importações comuns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd # pandas is a data manipulation library\n",
    "import random\n",
    "from wordcloud import WordCloud, STOPWORDS #used to generate world cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6CD-_tpA7o_"
   },
   "outputs": [],
   "source": [
    "#Para garantir estabilidade e ser mais fácil reproduzir experimento\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XilT7mJA-fx"
   },
   "outputs": [],
   "source": [
    "# Para plotar figuras\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDgr37xgBVsA"
   },
   "source": [
    "[Confira aqui](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.rc.html) a documentação do matplotlib.rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTuMQUrzBBrl"
   },
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zwbr171pBB2O"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ignorar warnings desnecessários (ver SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBjzryXYKMb5"
   },
   "source": [
    "# 2. Enquadar o problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0G56JZx56qrZ"
   },
   "source": [
    "- Qual o objetivo do problema?\n",
    "\n",
    "- Como a empresa/cliente pretende usar o produto?\n",
    "\n",
    "Tais perguntas são importantes pois definirá como você vai abordar o problema, que tipo de algoritmo irá usar e quais [medidas de desempenho](http://geam.paginas.ufsc.br/files/2020/02/Medida-desempenho-regressaob.pdf) são mais relevantes. \n",
    "\n",
    "// Obs. 1: Comparar interpretação geográfica de cada métrica (MAE, MSE e RMSE). Plotar as 3 retas no mesmo gráfico.\n",
    "\n",
    "Você precisará avaliar se a solução requer uma solução muito complexa, que demandará mais trabalho, tempo e dinheiro, ou se uma solução mais simples será suficiente.\n",
    "\n",
    "Recomendação de filmes.\n",
    "\n",
    "1) Predizer o valor da avaliação de usuário para filme assistido.\n",
    "\n",
    "2) Classificar se um filme será ou não assistido pelo usuário.\n",
    "\n",
    "3) Recomendar um grupo de filmes com maior possibilidade de escolha do usuário e maior diversidade entre os filmes.\n",
    "\n",
    "4) Modelo com maior satisfação do cliente/empresa?!\n",
    "\n",
    "// Navalha de Okan: se você tem 2 soluções que satisfazem o problema, deve ser escolhida a mais simples. (como propor deep learning e sistemas baseados em conhecimento? Quando eles são realmente necessários?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMaugIFD5xmR"
   },
   "source": [
    " ## Dicas\n",
    "\n",
    "- Não aborde, em um primeiro momento, um problema usando a solução mais complexa possível. Otimização prematura é arriscado e pode comprometer o projeto;\n",
    "\n",
    "- Leve em consideração que os modelos mais complexos são mais difíceis de manter, requer estruturas mais sofisticadas (e mais caras) e geralmente requer um corpo técnico mais qualificado - fique atento também as regulamentações dos dados;\n",
    "\n",
    "- Comece com protótipos rápidos e vá conversando com o cliente obtendo retorno sobre as necessidades do produto. Já pensou passar meses desenvolvendo um produto e no final não era o que o cliente queria? A agilidade em fazer protótipos em Python torna essa linguagem muito interessante!\n",
    "\n",
    "- As nossas visões, opiniões vão mudando com o tempo, então é natural que o cliente (e você!) vá amadurecendo ao longo do processo. Então, repetindo, sempre se comunique para atender a necessidade do projeto!\n",
    "\n",
    "- Antes de começar a trabalhar no projeto, verifique todas as hipóteses do sistema, infraestrutura disponível, linguagens de programação que serão utilizada, plataformas, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. ML1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Obter os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7N5Z56F8Mw3"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "from six.moves import urllib\n",
    "\n",
    "ML1M_ROOT = \"http://files.grouplens.org/datasets/movielens/\"\n",
    "ML1M_PATH = os.path.join(\"..\", \"..\", \"datasets\", \"ml1m\")\n",
    "ML1M_FILE =  \"ml-1m.zip\"\n",
    "ML1M_MD5 = ML1M_ROOT + ML1M_FILE + \".md5\"\n",
    "\n",
    "def fetch_ml1m_data(filename=ML1M_FILE, download_root=ML1M_ROOT, save_path=ML1M_PATH):\n",
    "    os.makedirs(save_path, exist_ok=True) #Cria diretorio\n",
    "    file_path = os.path.join(save_path, filename) #caminho do arquivo\n",
    "    download_url = os.path.join(download_root, filename) #url do arquivo\n",
    "    urllib.request.urlretrieve(download_url, file_path)\n",
    "    with ZipFile(file_path) as ml1m_zip:\n",
    "        ml1m_zip.extractall(path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InzGdJMr8Mw_",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_ml1m_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5d60f86f08c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfetch_ml1m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Cria diretório datasets/ml1m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fetch_ml1m_data' is not defined"
     ]
    }
   ],
   "source": [
    "fetch_ml1m_data() #Cria diretório datasets/ml1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdF8chZz8MxH"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cesarcf1977/movielens-data-analysis-beginner-s-first\n",
    "# from http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/\n",
    "def load_ml1m_data(save_path=ML1M_PATH):\n",
    "    # pass in column names for each CSV\n",
    "    csv_path = os.path.join(save_path, \"ml-1m\", \"users.dat\")\n",
    "    u_cols = ['user_id', 'gender', 'age', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv(csv_path, sep='::', engine=\"python\", names=u_cols, encoding='utf8')\n",
    "\n",
    "    csv_path = os.path.join(save_path, \"ml-1m\", \"ratings.dat\")\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv(csv_path, sep='::', engine=\"python\", names=r_cols, encoding='utf8')\n",
    "\n",
    "    # the movies file contains columns indicating the movie's genres\n",
    "    # let's only load the first five columns of the file with usecols\n",
    "    csv_path = os.path.join(save_path, \"ml-1m\", \"movies.dat\")\n",
    "    m_cols = ['movie_id', 'title', 'genres']\n",
    "    movies = pd.read_csv(csv_path, sep=\"::\", engine=\"python\", names=m_cols, usecols=range(5), encoding='latin-1')\n",
    "\n",
    "    # create one merged DataFrame\n",
    "    movie_ratings = pd.merge(movies, ratings)\n",
    "    lens = pd.merge(movie_ratings, users)\n",
    "    return users, ratings, movies, movie_ratings, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAw-T6N88MxQ",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>Pocahontas (1995)</td>\n",
       "      <td>Animation|Children's|Musical|Romance</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>Apollo 13 (1995)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>978301777</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>978300760</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527</td>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>Drama|War</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>978824195</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                      title  \\\n",
       "0         1                           Toy Story (1995)   \n",
       "1        48                          Pocahontas (1995)   \n",
       "2       150                           Apollo 13 (1995)   \n",
       "3       260  Star Wars: Episode IV - A New Hope (1977)   \n",
       "4       527                    Schindler's List (1993)   \n",
       "\n",
       "                                 genres  user_id  rating  unix_timestamp  \\\n",
       "0           Animation|Children's|Comedy        1       5       978824268   \n",
       "1  Animation|Children's|Musical|Romance        1       5       978824351   \n",
       "2                                 Drama        1       5       978301777   \n",
       "3       Action|Adventure|Fantasy|Sci-Fi        1       4       978300760   \n",
       "4                             Drama|War        1       5       978824195   \n",
       "\n",
       "  gender  age  occupation zip_code  \n",
       "0      F    1          10    48067  \n",
       "1      F    1          10    48067  \n",
       "2      F    1          10    48067  \n",
       "3      F    1          10    48067  \n",
       "4      F    1          10    48067  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users, ratings, movies, movie_ratings, lens = load_ml1m_data()\n",
    "lens.head() #visualizar as 5 primeiras linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae6oJj4R8MxZ"
   },
   "outputs": [],
   "source": [
    "lens.info() #Rápida descrição dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzN0Y0kpK8CQ"
   },
   "source": [
    "Arquivos ratings.dat, movies.dat e users.dat\n",
    "\n",
    "ratigns.dat: UserID::MovieID::Rating::Timestamp\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings\n",
    "\n",
    "users.dat: UserID::Gender::Age::Occupation::Zip-code\n",
    "\n",
    "All demographic information is provided voluntarily by the users and is\n",
    "not checked for accuracy.  Only users who have provided some demographic\n",
    "information are included in this data set.\n",
    "\n",
    "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
    "- Age is chosen from the following ranges:\n",
    "\n",
    "\t*  1:  \"Under 18\"\n",
    "\t* 18:  \"18-24\"\n",
    "\t* 25:  \"25-34\"\n",
    "\t* 35:  \"35-44\"\n",
    "\t* 45:  \"45-49\"\n",
    "\t* 50:  \"50-55\"\n",
    "\t* 56:  \"56+\"\n",
    "- Occupation is chosen from the following choices:\n",
    "\t*  0:  \"other\" or not specified\n",
    "\t*  1:  \"academic/educator\"\n",
    "\t*  2:  \"artist\"\n",
    "\t*  3:  \"clerical/admin\"\n",
    "\t*  4:  \"college/grad student\"\n",
    "\t*  5:  \"customer service\"\n",
    "\t*  6:  \"doctor/health care\"\n",
    "\t*  7:  \"executive/managerial\"\n",
    "\t*  8:  \"farmer\"\n",
    "\t*  9:  \"homemaker\"\n",
    "\t* 10:  \"K-12 student\"\n",
    "\t* 11:  \"lawyer\"\n",
    "\t* 12:  \"programmer\"\n",
    "\t* 13:  \"retired\"\n",
    "\t* 14:  \"sales/marketing\"\n",
    "\t* 15:  \"scientist\"\n",
    "\t* 16:  \"self-employed\"\n",
    "\t* 17:  \"technician/engineer\"\n",
    "\t* 18:  \"tradesman/craftsman\"\n",
    "\t* 19:  \"unemployed\"\n",
    "\t* 20:  \"writer\"\n",
    "    \n",
    "movies.dat: MovieID::Title::Genres\n",
    "- Titles are identical to titles provided by the IMDB (including\n",
    "year of release)\n",
    "- Genres are pipe-separated and are selected from the following genres:\n",
    "\t* Action\n",
    "\t* Adventure\n",
    "\t* Animation\n",
    "\t* Children's\n",
    "\t* Comedy\n",
    "\t* Crime\n",
    "\t* Documentary\n",
    "\t* Drama\n",
    "\t* Fantasy\n",
    "\t* Film-Noir\n",
    "\t* Horror\n",
    "\t* Musical\n",
    "\t* Mystery\n",
    "\t* Romance\n",
    "\t* Sci-Fi\n",
    "\t* Thriller\n",
    "\t* War\n",
    "\t* Western\n",
    "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
    "entries and/or test entries\n",
    "- Movies are mostly entered by hand, so errors and inconsistencies may exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUqXwjN_8Mxo"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3020.500000</td>\n",
       "      <td>30.639238</td>\n",
       "      <td>8.146854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1743.742145</td>\n",
       "      <td>12.895962</td>\n",
       "      <td>6.329511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1510.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3020.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4530.250000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id          age   occupation\n",
       "count  6040.000000  6040.000000  6040.000000\n",
       "mean   3020.500000    30.639238     8.146854\n",
       "std    1743.742145    12.895962     6.329511\n",
       "min       1.000000     1.000000     0.000000\n",
       "25%    1510.750000    25.000000     3.000000\n",
       "50%    3020.500000    25.000000     7.000000\n",
       "75%    4530.250000    35.000000    14.000000\n",
       "max    6040.000000    56.000000    20.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.describe() #Medidas resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000209e+06</td>\n",
       "      <td>1.000209e+06</td>\n",
       "      <td>1.000209e+06</td>\n",
       "      <td>1.000209e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.024512e+03</td>\n",
       "      <td>1.865540e+03</td>\n",
       "      <td>3.581564e+00</td>\n",
       "      <td>9.722437e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.728413e+03</td>\n",
       "      <td>1.096041e+03</td>\n",
       "      <td>1.117102e+00</td>\n",
       "      <td>1.215256e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.567039e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.506000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.653026e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.070000e+03</td>\n",
       "      <td>1.835000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>9.730180e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.476000e+03</td>\n",
       "      <td>2.770000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>9.752209e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.040000e+03</td>\n",
       "      <td>3.952000e+03</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.046455e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id      movie_id        rating  unix_timestamp\n",
       "count  1.000209e+06  1.000209e+06  1.000209e+06    1.000209e+06\n",
       "mean   3.024512e+03  1.865540e+03  3.581564e+00    9.722437e+08\n",
       "std    1.728413e+03  1.096041e+03  1.117102e+00    1.215256e+07\n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00    9.567039e+08\n",
       "25%    1.506000e+03  1.030000e+03  3.000000e+00    9.653026e+08\n",
       "50%    3.070000e+03  1.835000e+03  4.000000e+00    9.730180e+08\n",
       "75%    4.476000e+03  2.770000e+03  4.000000e+00    9.752209e+08\n",
       "max    6.040000e+03  3.952000e+03  5.000000e+00    1.046455e+09"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.describe() #Medidas resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3883.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1986.049446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1146.778349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>982.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2980.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3952.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id\n",
       "count  3883.000000\n",
       "mean   1986.049446\n",
       "std    1146.778349\n",
       "min       1.000000\n",
       "25%     982.500000\n",
       "50%    2010.000000\n",
       "75%    2980.500000\n",
       "max    3952.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe() #Medidas resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZyjfvEmJBZk"
   },
   "source": [
    "4 características são categóricas: title, genres, gender e zip_code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPr0m4-t8Mxg"
   },
   "outputs": [],
   "source": [
    "movies[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada um dos 3883 filmes possui um título distinto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"genres\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8TL_7-vJhCN"
   },
   "source": [
    "Como podemos observar, a característica \"genres\" é uma variável multivalorada, com 301 combinações de 18 gêneros de filmes. Podemos analisar desta forma (nome bonito que não lembro que define clases que significam combinações de classes menores) ou tratar os 18 generos como OneHotEncoder (ver se dá de usar esse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://www.kaggle.com/jneupane12/analysis-of-movielens-dataset-beginner-sanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that counts the number of times each genre appear:\n",
    "def count_word(df, ref_col, liste):\n",
    "    keyword_count = dict()\n",
    "    for s in liste: keyword_count[s] = 0\n",
    "    for liste_keywords in df[ref_col].str.split('|'):\n",
    "        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue\n",
    "        for s in liste_keywords: \n",
    "            if pd.notnull(s): keyword_count[s] += 1\n",
    "    # convert the dictionary in a list to sort the keywords  by frequency\n",
    "    keyword_occurences = []\n",
    "    for k,v in keyword_count.items():\n",
    "        keyword_occurences.append([k,v])\n",
    "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
    "    return keyword_occurences, keyword_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we  make census of the genres:\n",
    "genre_labels = set()\n",
    "for s in movies['genres'].str.split('|').values:\n",
    "    genre_labels = genre_labels.union(set(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting how many times each of genres occur:\n",
    "keyword_occurences, dum = count_word(movies, 'genres', genre_labels)\n",
    "keyword_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"OneHotEncode\" para genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_unique = pd.DataFrame(movies.genres.str.split('|').tolist()).stack().unique()\n",
    "genres_unique = pd.DataFrame(genres_unique, columns=['genre']) # Format into DataFrame to store later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movies = movies.join(movies.genres.str.get_dummies())\n",
    "new_movies.drop('genres', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[\"zip_code\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. Cleanning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is any row null\n",
    "users.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is any row null\n",
    "movies.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is any row null\n",
    "ratings.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaNOxfbs8Mxv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "users.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "ratings.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "movies.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function that control the color of the words\n",
    "def random_color_func(word=None, font_size=None, position=None,\n",
    "                      orientation=None, font_path=None, random_state=None):\n",
    "    h = int(360.0 * tone / 255.0)\n",
    "    s = int(100.0 * 255.0 / 255.0)\n",
    "    l = int(100.0 * float(random_state.randint(70, 120)) / 255.0)\n",
    "    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n",
    "\n",
    "\n",
    "#Finally, the result is shown as a wordcloud:\n",
    "words = dict()\n",
    "trunc_occurences = keyword_occurences[0:50]\n",
    "for s in trunc_occurences:\n",
    "    words[s[0]] = s[1]\n",
    "tone = 100 # define the color of the words\n",
    "f, ax = plt.subplots(figsize=(14, 6))\n",
    "wordcloud = WordCloud(width=550,height=300, background_color='black', \n",
    "                      max_words=1628,relative_scaling=0.7,\n",
    "                      color_func = random_color_func,\n",
    "                      normalize_plurals=False)\n",
    "wordcloud.generate_from_frequencies(words)\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets display the same result in the histogram\n",
    "fig = plt.figure(1, figsize=(18,13))\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "y_axis = [i[1] for i in trunc_occurences]\n",
    "x_axis = [k for k,i in enumerate(trunc_occurences)]\n",
    "x_label = [i[0] for i in trunc_occurences]\n",
    "plt.xticks(rotation=85, fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xticks(x_axis, x_label)\n",
    "plt.ylabel(\"No. of occurences\", fontsize = 24, labelpad = 0)\n",
    "ax2.bar(x_axis, y_axis, align = 'center', color='r')\n",
    "plt.title(\"Popularity of Genres\",bbox={'facecolor':'k', 'pad':5},color='w',fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. ml1m-cao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Obter os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cesarcf1977/movielens-data-analysis-beginner-s-first\n",
    "# from http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/\n",
    "CAO_PATH = os.path.join(\"..\", \"..\", \"datasets\", \"ml1m-cao\")\n",
    "def load_ml1m_cao_data(save_path=CAO_PATH):\n",
    "    # pass in column names for each CSV\n",
    "    # rating files: train, valid and test\n",
    "    r_cols = ['user_id', 'item_id', 'rating']\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"train.dat\")\n",
    "    train = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=r_cols, encoding='utf8')\n",
    "\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"valid.dat\")\n",
    "    valid = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=r_cols, encoding='utf8')\n",
    "\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"test.dat\")\n",
    "    test = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=r_cols, encoding='utf8')\n",
    "\n",
    "    frames = [train, valid, test]\n",
    "    ratings = pd.concat(frames)\n",
    "    \n",
    "    # kg files: train, valid and test\n",
    "    kg_cols = ['sub_id', 'obj_id', 'pred_id']\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"kg\", \"train.dat\")\n",
    "    kg_train = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=kg_cols, encoding='utf8')\n",
    "\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"kg\", \"valid.dat\")\n",
    "    kg_valid = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=kg_cols, encoding='utf8')\n",
    "\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"kg\", \"test.dat\")\n",
    "    kg_test = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=kg_cols, encoding='utf8')\n",
    "\n",
    "    frames = [kg_train, kg_valid, kg_test]\n",
    "    kg = pd.concat(frames)\n",
    "    \n",
    "    # map files: i_map, i2kg_map and e_map\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"i_map.dat\")\n",
    "    u_cols = ['mapped_id', 'orig_id']\n",
    "    i_map = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=u_cols, encoding='utf8')\n",
    "\n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"i2kg_map.tsv\")\n",
    "    r_cols = ['orig_id', 'name', 'uri']\n",
    "    i2kg_map = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=r_cols, encoding='utf8')\n",
    "    \n",
    "    csv_path = os.path.join(save_path, \"ml1m\", \"kg\", \"e_map.dat\")\n",
    "    r_cols = ['e_id', 'uri']\n",
    "    e_map = pd.read_csv(csv_path, sep='\\t', engine=\"python\", names=r_cols, encoding='utf8')\n",
    "\n",
    "    # create one merged DataFrame\n",
    "    return train, valid, test, ratings, kg_train, kg_valid, kg_test, kg, i_map, i2kg_map, e_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test, ratings, kg_train, kg_valid, kg_test, kg, i_map, i2kg_map, e_map = load_ml1m_cao_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 998539 entries, 0 to 193630\n",
      "Data columns (total 3 columns):\n",
      "user_id    998539 non-null int64\n",
      "item_id    998539 non-null int64\n",
      "rating     998539 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 30.5 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 434189 entries, 0 to 86834\n",
      "Data columns (total 3 columns):\n",
      "sub_id     434189 non-null int64\n",
      "obj_id     434189 non-null int64\n",
      "pred_id    434189 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 13.3 MB\n"
     ]
    }
   ],
   "source": [
    "kg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3260 entries, 0 to 3259\n",
      "Data columns (total 2 columns):\n",
      "mapped_id    3260 non-null int64\n",
      "orig_id      3260 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 51.0 KB\n"
     ]
    }
   ],
   "source": [
    "i_map.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3301 entries, 0 to 3300\n",
      "Data columns (total 3 columns):\n",
      "orig_id    3301 non-null int64\n",
      "name       3301 non-null object\n",
      "uri        3301 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 77.4+ KB\n"
     ]
    }
   ],
   "source": [
    "i2kg_map.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14708 entries, 0 to 14707\n",
      "Data columns (total 2 columns):\n",
      "e_id    14708 non-null int64\n",
      "uri     14708 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 229.9+ KB\n"
     ]
    }
   ],
   "source": [
    "e_map.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_map.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2kg_map.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_map.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2343    3428\n",
       "232     2991\n",
       "951     2990\n",
       "965     2883\n",
       "434     2672\n",
       "1618    2653\n",
       "531     2649\n",
       "2094    2590\n",
       "1023    2583\n",
       "534     2578\n",
       "1261    2538\n",
       "953     2514\n",
       "545     2513\n",
       "2260    2459\n",
       "97      2443\n",
       "1939    2369\n",
       "952     2318\n",
       "480     2304\n",
       "1297    2288\n",
       "1018    2278\n",
       "886     2269\n",
       "2137    2250\n",
       "2466    2241\n",
       "284     2227\n",
       "689     2223\n",
       "321     2194\n",
       "2216    2181\n",
       "264     2171\n",
       "993     2098\n",
       "0       2077\n",
       "        ... \n",
       "2140      11\n",
       "1466      11\n",
       "839       11\n",
       "2836      10\n",
       "2477      10\n",
       "1495      10\n",
       "2696      10\n",
       "598       10\n",
       "2326      10\n",
       "2182      10\n",
       "3204      10\n",
       "2463      10\n",
       "2929      10\n",
       "2279      10\n",
       "1791      10\n",
       "216       10\n",
       "215       10\n",
       "1394      10\n",
       "2409      10\n",
       "1472      10\n",
       "1773      10\n",
       "2340      10\n",
       "690       10\n",
       "938       10\n",
       "2856      10\n",
       "693       10\n",
       "350       10\n",
       "2433      10\n",
       "1786      10\n",
       "652       10\n",
       "Name: mapped_id, Length: 3260, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = os.path.join(\"..\", \"..\", \"datasets\", \"ml1m-cao2sun\", \"ml1m\", \"rating-delete-missing-itemid.txt\")\n",
    "rdmi = pd.read_csv(csv, sep='\\t', engine=\"python\", names=['u', 'mapped_id', 'r', 't'], encoding='utf8')\n",
    "rdmi['mapped_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_id</th>\n",
       "      <th>orig_id</th>\n",
       "      <th>u</th>\n",
       "      <th>r</th>\n",
       "      <th>t</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mapped_id, orig_id, u, r, t, _merge]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = i_map.merge(rdmi, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only'] \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_id</th>\n",
       "      <th>name</th>\n",
       "      <th>uri</th>\n",
       "      <th>mapped_id</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1705</td>\n",
       "      <td>Guy (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Guy_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>834</td>\n",
       "      <td>Phat Beach (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Phat_Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2244</td>\n",
       "      <td>Allnighter, The (1987)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Allnighter_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1577</td>\n",
       "      <td>Mondo (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Mondo_cane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3944</td>\n",
       "      <td>Bootmen (2000)</td>\n",
       "      <td>http://dbpedia.org/resource/Bootmen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1434</td>\n",
       "      <td>Stranger, The (1994)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Stranger_(1995...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3346</td>\n",
       "      <td>Color Me Blood Red (1965)</td>\n",
       "      <td>http://dbpedia.org/resource/Color_Me_Blood_Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>120</td>\n",
       "      <td>Race the Sun (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Race_the_Sun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3166</td>\n",
       "      <td>Brenda Starr (1989)</td>\n",
       "      <td>http://dbpedia.org/resource/Brenda_Starr_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1579</td>\n",
       "      <td>For Ever Mozart (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/For_Ever_Mozart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3803</td>\n",
       "      <td>Greaser's Palace (1972)</td>\n",
       "      <td>http://dbpedia.org/resource/Greaser's_Palace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2556</td>\n",
       "      <td>Telling You (1998)</td>\n",
       "      <td>http://dbpedia.org/resource/Telling_You</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3295</td>\n",
       "      <td>Raining Stones (1993)</td>\n",
       "      <td>http://dbpedia.org/resource/Raining_Stones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2438</td>\n",
       "      <td>Outside Ozona (1998)</td>\n",
       "      <td>http://dbpedia.org/resource/Outside_Ozona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3348</td>\n",
       "      <td>Night Visitor, The (1970)</td>\n",
       "      <td>http://dbpedia.org/resource/Night_Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2765</td>\n",
       "      <td>Acid House, The (1998)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Acid_House_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1311</td>\n",
       "      <td>Santa with Muscles (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Santa_with_Muscles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>557</td>\n",
       "      <td>Mamma Roma (1962)</td>\n",
       "      <td>http://dbpedia.org/resource/Mamma_Roma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3297</td>\n",
       "      <td>With Byrd at the South Pole (1930)</td>\n",
       "      <td>http://dbpedia.org/resource/With_Byrd_at_the_S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1052</td>\n",
       "      <td>Proprietor, The (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Proprietor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>787</td>\n",
       "      <td>Gate of Heavenly Peace, The (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Gate_of_Heaven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2954</td>\n",
       "      <td>Penitentiary (1979)</td>\n",
       "      <td>http://dbpedia.org/resource/Penitentiary_(1979...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1718</td>\n",
       "      <td>Stranger in the House (1997)</td>\n",
       "      <td>http://dbpedia.org/resource/Stranger_in_the_Ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1486</td>\n",
       "      <td>Quiet Room, The (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Quiet_Room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>33</td>\n",
       "      <td>Wings of Courage (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Wings_of_Courage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>396</td>\n",
       "      <td>Fall Time (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Fall_Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1314</td>\n",
       "      <td>Breathing Room (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Breathing_Room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2955</td>\n",
       "      <td>Penitentiary II (1982)</td>\n",
       "      <td>http://dbpedia.org/resource/Penitentiary_II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>167</td>\n",
       "      <td>Feast of July (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Feast_of_July</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3561</td>\n",
       "      <td>Stacy's Knights (1982)</td>\n",
       "      <td>http://dbpedia.org/resource/Stacy's_Knights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>3293</td>\n",
       "      <td>Conceiving Ada (1997)</td>\n",
       "      <td>http://dbpedia.org/resource/Conceiving_Ada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>1424</td>\n",
       "      <td>Inside (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Inside_Man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>630</td>\n",
       "      <td>Carried Away (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Carried_Away_(1996...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>2508</td>\n",
       "      <td>Breaks, The (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/When_the_Bough_Bre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>3294</td>\n",
       "      <td>Eaten Alive (1976)</td>\n",
       "      <td>http://dbpedia.org/resource/Eaten_Alive!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>2510</td>\n",
       "      <td>Just the Ticket (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/Just_the_Ticket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>634</td>\n",
       "      <td>Theodore Rex (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Theodore_Rex_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>636</td>\n",
       "      <td>Frisk (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Frisk_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>2228</td>\n",
       "      <td>Mountain Eagle, The (1926)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Mountain_Eagle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>1174</td>\n",
       "      <td>Grosse Fatigue (1994)</td>\n",
       "      <td>http://dbpedia.org/resource/Grosse_Fatigue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>2623</td>\n",
       "      <td>Trippin' (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/Trippin'_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>1002</td>\n",
       "      <td>Ed's Next Move (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Ed's_Next_Move</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>641</td>\n",
       "      <td>Little Indian, Big City (Un indien dans la vil...</td>\n",
       "      <td>http://dbpedia.org/resource/Un_indien_dans_la_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>2229</td>\n",
       "      <td>Pleasure Garden, The (1925)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Pleasure_Garde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>98</td>\n",
       "      <td>Shopping (1994)</td>\n",
       "      <td>http://dbpedia.org/resource/Shopping_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>2230</td>\n",
       "      <td>Always Tell Your Wife (1923)</td>\n",
       "      <td>http://dbpedia.org/resource/Always_Tell_Your_Wife</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>1567</td>\n",
       "      <td>Last Time I Committed Suicide, The (1997)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Last_Time_I_Co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>3541</td>\n",
       "      <td>Third World Cop (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/Third_World_Cop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>1430</td>\n",
       "      <td>Underworld (1997)</td>\n",
       "      <td>http://dbpedia.org/resource/Underworld_(1927_f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>1698</td>\n",
       "      <td>Boys, Les (1997)</td>\n",
       "      <td>http://dbpedia.org/resource/Les_Boys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>1568</td>\n",
       "      <td>MURDER and murder (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Murder_Me,_Murder_You</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>2233</td>\n",
       "      <td>Digging to China (1998)</td>\n",
       "      <td>http://dbpedia.org/resource/Digging_to_China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>2234</td>\n",
       "      <td>Let's Talk About Sex (1998)</td>\n",
       "      <td>http://dbpedia.org/resource/Let's_Talk_About_S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>2235</td>\n",
       "      <td>One Man's Hero (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/One_Man's_Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>2631</td>\n",
       "      <td>Frogs for Snakes (1998)</td>\n",
       "      <td>http://dbpedia.org/resource/Frogs_for_Snakes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>108</td>\n",
       "      <td>Catwalk (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Catwalk_Dogs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>777</td>\n",
       "      <td>Pharaoh's Army (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Pharaoh's_Army</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>1433</td>\n",
       "      <td>Machine, The (1994)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Time_Machine_(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>115</td>\n",
       "      <td>Happiness Is in the Field (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Happiness_Is_in_th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>2242</td>\n",
       "      <td>Grandview, U.S.A. (1984)</td>\n",
       "      <td>http://dbpedia.org/resource/Grandview,_U.S.A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_id                                               name  \\\n",
       "20       1705                                         Guy (1996)   \n",
       "26        834                                  Phat Beach (1996)   \n",
       "34       2244                             Allnighter, The (1987)   \n",
       "45       1577                                       Mondo (1996)   \n",
       "57       3944                                     Bootmen (2000)   \n",
       "88       1434                               Stranger, The (1994)   \n",
       "90       3346                          Color Me Blood Red (1965)   \n",
       "96        120                                Race the Sun (1996)   \n",
       "97       3166                                Brenda Starr (1989)   \n",
       "116      1579                             For Ever Mozart (1996)   \n",
       "122      3803                            Greaser's Palace (1972)   \n",
       "129      2556                                 Telling You (1998)   \n",
       "138      3295                              Raining Stones (1993)   \n",
       "151      2438                               Outside Ozona (1998)   \n",
       "154      3348                          Night Visitor, The (1970)   \n",
       "168      2765                             Acid House, The (1998)   \n",
       "236      1311                          Santa with Muscles (1996)   \n",
       "238       557                                  Mamma Roma (1962)   \n",
       "239      3297                 With Byrd at the South Pole (1930)   \n",
       "248      1052                             Proprietor, The (1996)   \n",
       "263       787                 Gate of Heavenly Peace, The (1995)   \n",
       "272      2954                                Penitentiary (1979)   \n",
       "279      1718                       Stranger in the House (1997)   \n",
       "290      1486                             Quiet Room, The (1996)   \n",
       "303        33                            Wings of Courage (1995)   \n",
       "319       396                                   Fall Time (1995)   \n",
       "328      1314                              Breathing Room (1996)   \n",
       "330      2955                             Penitentiary II (1982)   \n",
       "347       167                               Feast of July (1995)   \n",
       "354      3561                             Stacy's Knights (1982)   \n",
       "...       ...                                                ...   \n",
       "3005     3293                              Conceiving Ada (1997)   \n",
       "3008     1424                                      Inside (1996)   \n",
       "3012      630                                Carried Away (1996)   \n",
       "3022     2508                                 Breaks, The (1999)   \n",
       "3026     3294                                 Eaten Alive (1976)   \n",
       "3037     2510                             Just the Ticket (1999)   \n",
       "3045      634                                Theodore Rex (1995)   \n",
       "3060      636                                       Frisk (1995)   \n",
       "3068     2228                         Mountain Eagle, The (1926)   \n",
       "3071     1174                              Grosse Fatigue (1994)   \n",
       "3082     2623                                    Trippin' (1999)   \n",
       "3087     1002                              Ed's Next Move (1996)   \n",
       "3093      641  Little Indian, Big City (Un indien dans la vil...   \n",
       "3094     2229                        Pleasure Garden, The (1925)   \n",
       "3103       98                                    Shopping (1994)   \n",
       "3104     2230                       Always Tell Your Wife (1923)   \n",
       "3122     1567          Last Time I Committed Suicide, The (1997)   \n",
       "3150     3541                             Third World Cop (1999)   \n",
       "3156     1430                                  Underworld (1997)   \n",
       "3159     1698                                   Boys, Les (1997)   \n",
       "3167     1568                           MURDER and murder (1996)   \n",
       "3168     2233                            Digging to China (1998)   \n",
       "3175     2234                        Let's Talk About Sex (1998)   \n",
       "3186     2235                              One Man's Hero (1999)   \n",
       "3187     2631                            Frogs for Snakes (1998)   \n",
       "3201      108                                     Catwalk (1995)   \n",
       "3254      777                              Pharaoh's Army (1995)   \n",
       "3257     1433                                Machine, The (1994)   \n",
       "3293      115                   Happiness Is in the Field (1995)   \n",
       "3298     2242                           Grandview, U.S.A. (1984)   \n",
       "\n",
       "                                                    uri  mapped_id     _merge  \n",
       "20               http://dbpedia.org/resource/Guy_(film)        NaN  left_only  \n",
       "26               http://dbpedia.org/resource/Phat_Beach        NaN  left_only  \n",
       "34    http://dbpedia.org/resource/The_Allnighter_(film)        NaN  left_only  \n",
       "45               http://dbpedia.org/resource/Mondo_cane        NaN  left_only  \n",
       "57                  http://dbpedia.org/resource/Bootmen        NaN  left_only  \n",
       "88    http://dbpedia.org/resource/The_Stranger_(1995...        NaN  left_only  \n",
       "90       http://dbpedia.org/resource/Color_Me_Blood_Red        NaN  left_only  \n",
       "96             http://dbpedia.org/resource/Race_the_Sun        NaN  left_only  \n",
       "97      http://dbpedia.org/resource/Brenda_Starr_(film)        NaN  left_only  \n",
       "116         http://dbpedia.org/resource/For_Ever_Mozart        NaN  left_only  \n",
       "122        http://dbpedia.org/resource/Greaser's_Palace        NaN  left_only  \n",
       "129             http://dbpedia.org/resource/Telling_You        NaN  left_only  \n",
       "138          http://dbpedia.org/resource/Raining_Stones        NaN  left_only  \n",
       "151           http://dbpedia.org/resource/Outside_Ozona        NaN  left_only  \n",
       "154           http://dbpedia.org/resource/Night_Visitor        NaN  left_only  \n",
       "168   http://dbpedia.org/resource/The_Acid_House_(film)        NaN  left_only  \n",
       "236      http://dbpedia.org/resource/Santa_with_Muscles        NaN  left_only  \n",
       "238              http://dbpedia.org/resource/Mamma_Roma        NaN  left_only  \n",
       "239   http://dbpedia.org/resource/With_Byrd_at_the_S...        NaN  left_only  \n",
       "248          http://dbpedia.org/resource/The_Proprietor        NaN  left_only  \n",
       "263   http://dbpedia.org/resource/The_Gate_of_Heaven...        NaN  left_only  \n",
       "272   http://dbpedia.org/resource/Penitentiary_(1979...        NaN  left_only  \n",
       "279   http://dbpedia.org/resource/Stranger_in_the_Ho...        NaN  left_only  \n",
       "290          http://dbpedia.org/resource/The_Quiet_Room        NaN  left_only  \n",
       "303        http://dbpedia.org/resource/Wings_of_Courage        NaN  left_only  \n",
       "319               http://dbpedia.org/resource/Fall_Time        NaN  left_only  \n",
       "328          http://dbpedia.org/resource/Breathing_Room        NaN  left_only  \n",
       "330         http://dbpedia.org/resource/Penitentiary_II        NaN  left_only  \n",
       "347           http://dbpedia.org/resource/Feast_of_July        NaN  left_only  \n",
       "354         http://dbpedia.org/resource/Stacy's_Knights        NaN  left_only  \n",
       "...                                                 ...        ...        ...  \n",
       "3005         http://dbpedia.org/resource/Conceiving_Ada        NaN  left_only  \n",
       "3008             http://dbpedia.org/resource/Inside_Man        NaN  left_only  \n",
       "3012  http://dbpedia.org/resource/Carried_Away_(1996...        NaN  left_only  \n",
       "3022  http://dbpedia.org/resource/When_the_Bough_Bre...        NaN  left_only  \n",
       "3026           http://dbpedia.org/resource/Eaten_Alive!        NaN  left_only  \n",
       "3037        http://dbpedia.org/resource/Just_the_Ticket        NaN  left_only  \n",
       "3045    http://dbpedia.org/resource/Theodore_Rex_(film)        NaN  left_only  \n",
       "3060           http://dbpedia.org/resource/Frisk_(film)        NaN  left_only  \n",
       "3068     http://dbpedia.org/resource/The_Mountain_Eagle        NaN  left_only  \n",
       "3071         http://dbpedia.org/resource/Grosse_Fatigue        NaN  left_only  \n",
       "3082        http://dbpedia.org/resource/Trippin'_(film)        NaN  left_only  \n",
       "3087         http://dbpedia.org/resource/Ed's_Next_Move        NaN  left_only  \n",
       "3093  http://dbpedia.org/resource/Un_indien_dans_la_...        NaN  left_only  \n",
       "3094  http://dbpedia.org/resource/The_Pleasure_Garde...        NaN  left_only  \n",
       "3103        http://dbpedia.org/resource/Shopping_(film)        NaN  left_only  \n",
       "3104  http://dbpedia.org/resource/Always_Tell_Your_Wife        NaN  left_only  \n",
       "3122  http://dbpedia.org/resource/The_Last_Time_I_Co...        NaN  left_only  \n",
       "3150        http://dbpedia.org/resource/Third_World_Cop        NaN  left_only  \n",
       "3156  http://dbpedia.org/resource/Underworld_(1927_f...        NaN  left_only  \n",
       "3159               http://dbpedia.org/resource/Les_Boys        NaN  left_only  \n",
       "3167  http://dbpedia.org/resource/Murder_Me,_Murder_You        NaN  left_only  \n",
       "3168       http://dbpedia.org/resource/Digging_to_China        NaN  left_only  \n",
       "3175  http://dbpedia.org/resource/Let's_Talk_About_S...        NaN  left_only  \n",
       "3186         http://dbpedia.org/resource/One_Man's_Hero        NaN  left_only  \n",
       "3187       http://dbpedia.org/resource/Frogs_for_Snakes        NaN  left_only  \n",
       "3201           http://dbpedia.org/resource/Catwalk_Dogs        NaN  left_only  \n",
       "3254         http://dbpedia.org/resource/Pharaoh's_Army        NaN  left_only  \n",
       "3257  http://dbpedia.org/resource/The_Time_Machine_(...        NaN  left_only  \n",
       "3293  http://dbpedia.org/resource/Happiness_Is_in_th...        NaN  left_only  \n",
       "3298      http://dbpedia.org/resource/Grandview,_U.S.A.        NaN  left_only  \n",
       "\n",
       "[338 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = i2kg_map.merge(i_map, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only'] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "297 itens do i_map não tem correspondente no i2kg_map (left_only) e 338 itens do i2kg não aparecem no i_map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_id</th>\n",
       "      <th>orig_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3267.000000</td>\n",
       "      <td>3267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7437.302418</td>\n",
       "      <td>1986.993266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4240.117305</td>\n",
       "      <td>1143.429111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3794.500000</td>\n",
       "      <td>1012.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7404.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11244.500000</td>\n",
       "      <td>2964.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14698.000000</td>\n",
       "      <td>3951.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               e_id      orig_id\n",
       "count   3267.000000  3267.000000\n",
       "mean    7437.302418  1986.993266\n",
       "std     4240.117305  1143.429111\n",
       "min        5.000000     2.000000\n",
       "25%     3794.500000  1012.500000\n",
       "50%     7404.000000  2020.000000\n",
       "75%    11244.500000  2964.500000\n",
       "max    14698.000000  3951.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = e_map.merge(i2kg_map) \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_id</th>\n",
       "      <th>uri</th>\n",
       "      <th>orig_id</th>\n",
       "      <th>name</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>http://dbpedia.org/resource/Roger_Carel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>http://dbpedia.org/resource/Soundtrack_album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>http://dbpedia.org/resource/1982_in_film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:Films_set...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>http://dbpedia.org/resource/Plaza_Hotel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>http://dbpedia.org/resource/Buddy_Ebsen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>http://dbpedia.org/resource/Thomas_F._Duffy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>http://dbpedia.org/resource/Mutual_Film_Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>http://dbpedia.org/resource/List_of_anti-war_f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>http://dbpedia.org/resource/Robert_De_Niro_fil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>http://dbpedia.org/resource/Widescreen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>http://dbpedia.org/resource/Christine_Baranski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>http://dbpedia.org/resource/Paul_McCartney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>http://dbpedia.org/resource/Talisa_Soto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>http://dbpedia.org/resource/Paul_Calderón</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>http://dbpedia.org/resource/Vanessa_Redgrave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>http://dbpedia.org/resource/Santa_Claus_in_film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>http://dbpedia.org/resource/Kathleen_Wilhoite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>http://dbpedia.org/resource/Elliott_Gould</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:1971_films</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>http://dbpedia.org/resource/Brooke_Smith_(actr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>http://dbpedia.org/resource/Josh_Brolin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>http://dbpedia.org/class/yago/WikicatPublicDom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>http://dbpedia.org/resource/Adrienne_Fazan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:1990s_ind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.0</td>\n",
       "      <td>http://dbpedia.org/class/yago/Wikicat1958Films</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32.0</td>\n",
       "      <td>http://dbpedia.org/resource/1993_New_York_Film...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:Screenpla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:Palme_d'O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36.0</td>\n",
       "      <td>http://dbpedia.org/resource/List_of_fictional_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14671</th>\n",
       "      <td>14670.0</td>\n",
       "      <td>http://dbpedia.org/resource/Eric_Bernt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14672</th>\n",
       "      <td>14671.0</td>\n",
       "      <td>http://dbpedia.org/resource/David_O._Russell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14673</th>\n",
       "      <td>14672.0</td>\n",
       "      <td>http://dbpedia.org/resource/Asian_Americans_in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14674</th>\n",
       "      <td>14673.0</td>\n",
       "      <td>http://dbpedia.org/resource/Sci-Fi-London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14676</th>\n",
       "      <td>14675.0</td>\n",
       "      <td>http://dbpedia.org/resource/Chris_Owen_(actor)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14678</th>\n",
       "      <td>14677.0</td>\n",
       "      <td>http://dbpedia.org/resource/Psycho_(franchise)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14679</th>\n",
       "      <td>14678.0</td>\n",
       "      <td>http://dbpedia.org/resource/Colm_Meaney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14680</th>\n",
       "      <td>14679.0</td>\n",
       "      <td>http://dbpedia.org/resource/Musical_Memories_(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14682</th>\n",
       "      <td>14681.0</td>\n",
       "      <td>http://dbpedia.org/resource/Boone_Narr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14683</th>\n",
       "      <td>14682.0</td>\n",
       "      <td>http://dbpedia.org/resource/Stroke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14686</th>\n",
       "      <td>14685.0</td>\n",
       "      <td>http://dbpedia.org/resource/Paul_Rudnick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14687</th>\n",
       "      <td>14686.0</td>\n",
       "      <td>http://dbpedia.org/resource/Gossip_Girl_(seaso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14688</th>\n",
       "      <td>14687.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:Films_set...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14689</th>\n",
       "      <td>14688.0</td>\n",
       "      <td>http://dbpedia.org/resource/Incest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14690</th>\n",
       "      <td>14689.0</td>\n",
       "      <td>http://dbpedia.org/resource/Steven_Soderbergh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14691</th>\n",
       "      <td>14690.0</td>\n",
       "      <td>http://dbpedia.org/resource/How_Did_This_Get_M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14692</th>\n",
       "      <td>14691.0</td>\n",
       "      <td>http://dbpedia.org/resource/Robert_Duvall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>14692.0</td>\n",
       "      <td>http://dbpedia.org/resource/Bodil_Award_for_Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14694</th>\n",
       "      <td>14693.0</td>\n",
       "      <td>http://dbpedia.org/resource/List_of_ITC_Entert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14697</th>\n",
       "      <td>14696.0</td>\n",
       "      <td>http://dbpedia.org/resource/Thomas_Newman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14698</th>\n",
       "      <td>14697.0</td>\n",
       "      <td>http://dbpedia.org/resource/List_of_World_War_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14700</th>\n",
       "      <td>14699.0</td>\n",
       "      <td>http://dbpedia.org/resource/List_of_younger_an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14701</th>\n",
       "      <td>14700.0</td>\n",
       "      <td>http://dbpedia.org/resource/Boston_Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14702</th>\n",
       "      <td>14701.0</td>\n",
       "      <td>http://dbpedia.org/resource/John_Madden_(direc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14703</th>\n",
       "      <td>14702.0</td>\n",
       "      <td>http://dbpedia.org/resource/Christopher_Tellefsen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14704</th>\n",
       "      <td>14703.0</td>\n",
       "      <td>http://dbpedia.org/resource/Barry_Mann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14705</th>\n",
       "      <td>14704.0</td>\n",
       "      <td>http://dbpedia.org/resource/Metro-Goldwyn-Mayer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14706</th>\n",
       "      <td>14705.0</td>\n",
       "      <td>http://dbpedia.org/resource/Lee_J._Cobb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14707</th>\n",
       "      <td>14706.0</td>\n",
       "      <td>http://dbpedia.org/resource/Category:British_s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14708</th>\n",
       "      <td>14707.0</td>\n",
       "      <td>http://dbpedia.org/resource/Bill_Paxton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11442 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_id                                                uri  orig_id  \\\n",
       "0          0.0            http://dbpedia.org/resource/Roger_Carel      NaN   \n",
       "1          1.0       http://dbpedia.org/resource/Soundtrack_album      NaN   \n",
       "2          2.0           http://dbpedia.org/resource/1982_in_film      NaN   \n",
       "3          3.0  http://dbpedia.org/resource/Category:Films_set...      NaN   \n",
       "4          4.0            http://dbpedia.org/resource/Plaza_Hotel      NaN   \n",
       "6          6.0            http://dbpedia.org/resource/Buddy_Ebsen      NaN   \n",
       "8          8.0        http://dbpedia.org/resource/Thomas_F._Duffy      NaN   \n",
       "10        10.0    http://dbpedia.org/resource/Mutual_Film_Company      NaN   \n",
       "11        11.0  http://dbpedia.org/resource/List_of_anti-war_f...      NaN   \n",
       "12        12.0  http://dbpedia.org/resource/Robert_De_Niro_fil...      NaN   \n",
       "13        13.0             http://dbpedia.org/resource/Widescreen      NaN   \n",
       "14        14.0     http://dbpedia.org/resource/Christine_Baranski      NaN   \n",
       "15        15.0         http://dbpedia.org/resource/Paul_McCartney      NaN   \n",
       "17        17.0            http://dbpedia.org/resource/Talisa_Soto      NaN   \n",
       "18        18.0          http://dbpedia.org/resource/Paul_Calderón      NaN   \n",
       "19        19.0       http://dbpedia.org/resource/Vanessa_Redgrave      NaN   \n",
       "20        20.0    http://dbpedia.org/resource/Santa_Claus_in_film      NaN   \n",
       "21        21.0      http://dbpedia.org/resource/Kathleen_Wilhoite      NaN   \n",
       "22        22.0          http://dbpedia.org/resource/Elliott_Gould      NaN   \n",
       "23        23.0    http://dbpedia.org/resource/Category:1971_films      NaN   \n",
       "24        24.0  http://dbpedia.org/resource/Brooke_Smith_(actr...      NaN   \n",
       "25        25.0            http://dbpedia.org/resource/Josh_Brolin      NaN   \n",
       "26        26.0  http://dbpedia.org/class/yago/WikicatPublicDom...      NaN   \n",
       "27        27.0         http://dbpedia.org/resource/Adrienne_Fazan      NaN   \n",
       "28        28.0  http://dbpedia.org/resource/Category:1990s_ind...      NaN   \n",
       "30        30.0     http://dbpedia.org/class/yago/Wikicat1958Films      NaN   \n",
       "32        32.0  http://dbpedia.org/resource/1993_New_York_Film...      NaN   \n",
       "33        33.0  http://dbpedia.org/resource/Category:Screenpla...      NaN   \n",
       "35        35.0  http://dbpedia.org/resource/Category:Palme_d'O...      NaN   \n",
       "36        36.0  http://dbpedia.org/resource/List_of_fictional_...      NaN   \n",
       "...        ...                                                ...      ...   \n",
       "14671  14670.0             http://dbpedia.org/resource/Eric_Bernt      NaN   \n",
       "14672  14671.0       http://dbpedia.org/resource/David_O._Russell      NaN   \n",
       "14673  14672.0  http://dbpedia.org/resource/Asian_Americans_in...      NaN   \n",
       "14674  14673.0          http://dbpedia.org/resource/Sci-Fi-London      NaN   \n",
       "14676  14675.0     http://dbpedia.org/resource/Chris_Owen_(actor)      NaN   \n",
       "14678  14677.0     http://dbpedia.org/resource/Psycho_(franchise)      NaN   \n",
       "14679  14678.0            http://dbpedia.org/resource/Colm_Meaney      NaN   \n",
       "14680  14679.0  http://dbpedia.org/resource/Musical_Memories_(...      NaN   \n",
       "14682  14681.0             http://dbpedia.org/resource/Boone_Narr      NaN   \n",
       "14683  14682.0                 http://dbpedia.org/resource/Stroke      NaN   \n",
       "14686  14685.0           http://dbpedia.org/resource/Paul_Rudnick      NaN   \n",
       "14687  14686.0  http://dbpedia.org/resource/Gossip_Girl_(seaso...      NaN   \n",
       "14688  14687.0  http://dbpedia.org/resource/Category:Films_set...      NaN   \n",
       "14689  14688.0                 http://dbpedia.org/resource/Incest      NaN   \n",
       "14690  14689.0      http://dbpedia.org/resource/Steven_Soderbergh      NaN   \n",
       "14691  14690.0  http://dbpedia.org/resource/How_Did_This_Get_M...      NaN   \n",
       "14692  14691.0          http://dbpedia.org/resource/Robert_Duvall      NaN   \n",
       "14693  14692.0  http://dbpedia.org/resource/Bodil_Award_for_Be...      NaN   \n",
       "14694  14693.0  http://dbpedia.org/resource/List_of_ITC_Entert...      NaN   \n",
       "14697  14696.0          http://dbpedia.org/resource/Thomas_Newman      NaN   \n",
       "14698  14697.0  http://dbpedia.org/resource/List_of_World_War_...      NaN   \n",
       "14700  14699.0  http://dbpedia.org/resource/List_of_younger_an...      NaN   \n",
       "14701  14700.0           http://dbpedia.org/resource/Boston_Globe      NaN   \n",
       "14702  14701.0  http://dbpedia.org/resource/John_Madden_(direc...      NaN   \n",
       "14703  14702.0  http://dbpedia.org/resource/Christopher_Tellefsen      NaN   \n",
       "14704  14703.0             http://dbpedia.org/resource/Barry_Mann      NaN   \n",
       "14705  14704.0    http://dbpedia.org/resource/Metro-Goldwyn-Mayer      NaN   \n",
       "14706  14705.0            http://dbpedia.org/resource/Lee_J._Cobb      NaN   \n",
       "14707  14706.0  http://dbpedia.org/resource/Category:British_s...      NaN   \n",
       "14708  14707.0            http://dbpedia.org/resource/Bill_Paxton      NaN   \n",
       "\n",
       "      name     _merge  \n",
       "0      NaN  left_only  \n",
       "1      NaN  left_only  \n",
       "2      NaN  left_only  \n",
       "3      NaN  left_only  \n",
       "4      NaN  left_only  \n",
       "6      NaN  left_only  \n",
       "8      NaN  left_only  \n",
       "10     NaN  left_only  \n",
       "11     NaN  left_only  \n",
       "12     NaN  left_only  \n",
       "13     NaN  left_only  \n",
       "14     NaN  left_only  \n",
       "15     NaN  left_only  \n",
       "17     NaN  left_only  \n",
       "18     NaN  left_only  \n",
       "19     NaN  left_only  \n",
       "20     NaN  left_only  \n",
       "21     NaN  left_only  \n",
       "22     NaN  left_only  \n",
       "23     NaN  left_only  \n",
       "24     NaN  left_only  \n",
       "25     NaN  left_only  \n",
       "26     NaN  left_only  \n",
       "27     NaN  left_only  \n",
       "28     NaN  left_only  \n",
       "30     NaN  left_only  \n",
       "32     NaN  left_only  \n",
       "33     NaN  left_only  \n",
       "35     NaN  left_only  \n",
       "36     NaN  left_only  \n",
       "...    ...        ...  \n",
       "14671  NaN  left_only  \n",
       "14672  NaN  left_only  \n",
       "14673  NaN  left_only  \n",
       "14674  NaN  left_only  \n",
       "14676  NaN  left_only  \n",
       "14678  NaN  left_only  \n",
       "14679  NaN  left_only  \n",
       "14680  NaN  left_only  \n",
       "14682  NaN  left_only  \n",
       "14683  NaN  left_only  \n",
       "14686  NaN  left_only  \n",
       "14687  NaN  left_only  \n",
       "14688  NaN  left_only  \n",
       "14689  NaN  left_only  \n",
       "14690  NaN  left_only  \n",
       "14691  NaN  left_only  \n",
       "14692  NaN  left_only  \n",
       "14693  NaN  left_only  \n",
       "14694  NaN  left_only  \n",
       "14697  NaN  left_only  \n",
       "14698  NaN  left_only  \n",
       "14700  NaN  left_only  \n",
       "14701  NaN  left_only  \n",
       "14702  NaN  left_only  \n",
       "14703  NaN  left_only  \n",
       "14704  NaN  left_only  \n",
       "14705  NaN  left_only  \n",
       "14706  NaN  left_only  \n",
       "14707  NaN  left_only  \n",
       "14708  NaN  left_only  \n",
       "\n",
       "[11442 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = e_map.merge(i2kg_map, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only'] \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_id</th>\n",
       "      <th>name</th>\n",
       "      <th>uri</th>\n",
       "      <th>e_id</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2246.0</td>\n",
       "      <td>Stars and Bars (1988)</td>\n",
       "      <td>http://dbpedia.org/resource/Stars_and_bars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>441.0</td>\n",
       "      <td>Dazed and Confused (1993)</td>\n",
       "      <td>http://dbpedia.org/resource/Dazed_and_Confused</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3171.0</td>\n",
       "      <td>Room at the Top (1959)</td>\n",
       "      <td>http://dbpedia.org/resource/Room_at_the_Top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1298.0</td>\n",
       "      <td>Pink Floyd - The Wall (1982)</td>\n",
       "      <td>http://dbpedia.org/resource/Pink_Floyd_%25E2%2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1059.0</td>\n",
       "      <td>William Shakespeare's Romeo and Juliet (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Romeo__Juliet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2784.0</td>\n",
       "      <td>Masque of the Red Death, The (1964)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Masque_of_the_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/Sudden_Death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>3727.0</td>\n",
       "      <td>Near Dark (1987)</td>\n",
       "      <td>http://dbpedia.org/resource/Near_Dark_(2008_film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>2972.0</td>\n",
       "      <td>Red Sorghum (Hong Gao Liang) (1987)</td>\n",
       "      <td>http://dbpedia.org/resource/Red_Sorghum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>534.0</td>\n",
       "      <td>Shadowlands (1993)</td>\n",
       "      <td>http://dbpedia.org/resource/Shadowlands_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>579.0</td>\n",
       "      <td>Scorta, La (1993)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Escort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>3736.0</td>\n",
       "      <td>Big Carnival, The (1951)</td>\n",
       "      <td>http://dbpedia.org/resource/Ace_in_the_Hole_(f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>705.0</td>\n",
       "      <td>Cosi (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Cos%25C3%25AC_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>2577.0</td>\n",
       "      <td>Metroland (1997)</td>\n",
       "      <td>http://dbpedia.org/resource/Metro-Land_(TV_film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3075.0</td>\n",
       "      <td>Repulsion (1965)</td>\n",
       "      <td>http://dbpedia.org/resource/Repulsion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>3250.0</td>\n",
       "      <td>Alive (1993)</td>\n",
       "      <td>http://dbpedia.org/resource/Alive_(1983_film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>339.0</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "      <td>http://dbpedia.org/resource/While_You_Were_Sle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1396.0</td>\n",
       "      <td>Sneakers (1992)</td>\n",
       "      <td>http://dbpedia.org/resource/Sneaker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>3209.0</td>\n",
       "      <td>Loves of Carmen, The (1948)</td>\n",
       "      <td>http://dbpedia.org/resource/The_Loves_of_Carmen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>866.0</td>\n",
       "      <td>Bound (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Bound_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>3092.0</td>\n",
       "      <td>Chushingura (1962)</td>\n",
       "      <td>http://dbpedia.org/resource/Ch%25C5%25ABshingu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2206.0</td>\n",
       "      <td>Suspicion (1941)</td>\n",
       "      <td>http://dbpedia.org/resource/Suspicion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>723.0</td>\n",
       "      <td>Two Friends (1986)</td>\n",
       "      <td>http://dbpedia.org/resource/Two_Friends_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>726.0</td>\n",
       "      <td>Last Dance (1996)</td>\n",
       "      <td>http://dbpedia.org/resource/Last_Dance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2478.0</td>\n",
       "      <td>Three Amigos! (1986)</td>\n",
       "      <td>http://dbpedia.org/resource/%25C2%25A1Three_Am...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2722.0</td>\n",
       "      <td>Deep Blue Sea (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/Deep_Blue_Sea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>607.0</td>\n",
       "      <td>Century (1993)</td>\n",
       "      <td>http://dbpedia.org/resource/20th_Century_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>362.0</td>\n",
       "      <td>Jungle Book, The (1994)</td>\n",
       "      <td>http://dbpedia.org/resource/Rudyard_Kipling's_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>3522.0</td>\n",
       "      <td>Sacco and Vanzetti (Sacco e Vanzetti) (1971)</td>\n",
       "      <td>http://dbpedia.org/resource/Sacco_e_Vanzetti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>3659.0</td>\n",
       "      <td>Quatermass II (1957)</td>\n",
       "      <td>http://dbpedia.org/resource/Quatermass_II__Qua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>3538.0</td>\n",
       "      <td>East is East (1999)</td>\n",
       "      <td>http://dbpedia.org/resource/East_Is_East_(film)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>2756.0</td>\n",
       "      <td>Wanted: Dead or Alive (1987)</td>\n",
       "      <td>http://dbpedia.org/resource/Wanted_Dead_or_Alive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>3797.0</td>\n",
       "      <td>In Crowd, The (2000)</td>\n",
       "      <td>http://dbpedia.org/resource/The_In_Crowd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>3546.0</td>\n",
       "      <td>What Ever Happened to Baby Jane? (1962)</td>\n",
       "      <td>http://dbpedia.org/resource/What_Ever_Happened...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_id                                           name  \\\n",
       "66     2246.0                          Stars and Bars (1988)   \n",
       "145     441.0                      Dazed and Confused (1993)   \n",
       "233    3171.0                         Room at the Top (1959)   \n",
       "329    1298.0                   Pink Floyd - The Wall (1982)   \n",
       "415    1059.0  William Shakespeare's Romeo and Juliet (1996)   \n",
       "484    2784.0            Masque of the Red Death, The (1964)   \n",
       "819       9.0                            Sudden Death (1995)   \n",
       "820    3727.0                               Near Dark (1987)   \n",
       "1193   2972.0            Red Sorghum (Hong Gao Liang) (1987)   \n",
       "1250    534.0                             Shadowlands (1993)   \n",
       "1327    579.0                              Scorta, La (1993)   \n",
       "1333   3736.0                       Big Carnival, The (1951)   \n",
       "1412    705.0                                    Cosi (1996)   \n",
       "1532   2577.0                               Metroland (1997)   \n",
       "1596   3075.0                               Repulsion (1965)   \n",
       "1660   3250.0                                   Alive (1993)   \n",
       "1891    339.0                 While You Were Sleeping (1995)   \n",
       "1950   1396.0                                Sneakers (1992)   \n",
       "2041   3209.0                    Loves of Carmen, The (1948)   \n",
       "2156    866.0                                   Bound (1996)   \n",
       "2193   3092.0                             Chushingura (1962)   \n",
       "2197   2206.0                               Suspicion (1941)   \n",
       "2295    723.0                             Two Friends (1986)   \n",
       "2388    726.0                              Last Dance (1996)   \n",
       "2399   2478.0                           Three Amigos! (1986)   \n",
       "2450   2722.0                           Deep Blue Sea (1999)   \n",
       "2514    607.0                                 Century (1993)   \n",
       "2627    362.0                        Jungle Book, The (1994)   \n",
       "2681   3522.0   Sacco and Vanzetti (Sacco e Vanzetti) (1971)   \n",
       "2943   3659.0                           Quatermass II (1957)   \n",
       "3127   3538.0                            East is East (1999)   \n",
       "3158   2756.0                   Wanted: Dead or Alive (1987)   \n",
       "3268   3797.0                           In Crowd, The (2000)   \n",
       "3287   3546.0        What Ever Happened to Baby Jane? (1962)   \n",
       "\n",
       "                                                    uri  e_id     _merge  \n",
       "66           http://dbpedia.org/resource/Stars_and_bars   NaN  left_only  \n",
       "145      http://dbpedia.org/resource/Dazed_and_Confused   NaN  left_only  \n",
       "233         http://dbpedia.org/resource/Room_at_the_Top   NaN  left_only  \n",
       "329   http://dbpedia.org/resource/Pink_Floyd_%25E2%2...   NaN  left_only  \n",
       "415           http://dbpedia.org/resource/Romeo__Juliet   NaN  left_only  \n",
       "484   http://dbpedia.org/resource/The_Masque_of_the_...   NaN  left_only  \n",
       "819            http://dbpedia.org/resource/Sudden_Death   NaN  left_only  \n",
       "820   http://dbpedia.org/resource/Near_Dark_(2008_film)   NaN  left_only  \n",
       "1193            http://dbpedia.org/resource/Red_Sorghum   NaN  left_only  \n",
       "1250     http://dbpedia.org/resource/Shadowlands_(film)   NaN  left_only  \n",
       "1327             http://dbpedia.org/resource/The_Escort   NaN  left_only  \n",
       "1333  http://dbpedia.org/resource/Ace_in_the_Hole_(f...   NaN  left_only  \n",
       "1412   http://dbpedia.org/resource/Cos%25C3%25AC_(film)   NaN  left_only  \n",
       "1532   http://dbpedia.org/resource/Metro-Land_(TV_film)   NaN  left_only  \n",
       "1596              http://dbpedia.org/resource/Repulsion   NaN  left_only  \n",
       "1660      http://dbpedia.org/resource/Alive_(1983_film)   NaN  left_only  \n",
       "1891  http://dbpedia.org/resource/While_You_Were_Sle...   NaN  left_only  \n",
       "1950                http://dbpedia.org/resource/Sneaker   NaN  left_only  \n",
       "2041    http://dbpedia.org/resource/The_Loves_of_Carmen   NaN  left_only  \n",
       "2156           http://dbpedia.org/resource/Bound_(film)   NaN  left_only  \n",
       "2193  http://dbpedia.org/resource/Ch%25C5%25ABshingu...   NaN  left_only  \n",
       "2197              http://dbpedia.org/resource/Suspicion   NaN  left_only  \n",
       "2295     http://dbpedia.org/resource/Two_Friends_(film)   NaN  left_only  \n",
       "2388             http://dbpedia.org/resource/Last_Dance   NaN  left_only  \n",
       "2399  http://dbpedia.org/resource/%25C2%25A1Three_Am...   NaN  left_only  \n",
       "2450          http://dbpedia.org/resource/Deep_Blue_Sea   NaN  left_only  \n",
       "2514    http://dbpedia.org/resource/20th_Century_(film)   NaN  left_only  \n",
       "2627  http://dbpedia.org/resource/Rudyard_Kipling's_...   NaN  left_only  \n",
       "2681       http://dbpedia.org/resource/Sacco_e_Vanzetti   NaN  left_only  \n",
       "2943  http://dbpedia.org/resource/Quatermass_II__Qua...   NaN  left_only  \n",
       "3127    http://dbpedia.org/resource/East_Is_East_(film)   NaN  left_only  \n",
       "3158   http://dbpedia.org/resource/Wanted_Dead_or_Alive   NaN  left_only  \n",
       "3268           http://dbpedia.org/resource/The_In_Crowd   NaN  left_only  \n",
       "3287  http://dbpedia.org/resource/What_Ever_Happened...   NaN  left_only  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = i2kg_map.merge(e_map, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only'] \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Cleanning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5. Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2kg_map.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_map.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. ml1m-sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Obter os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Variáveis numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. Cleanning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4F7JWQ1BcEY"
   },
   "source": [
    "# Separando o conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGNLaRDmQX1d"
   },
   "source": [
    "Estratificação dos ratings, pois é importante ter um número suficiente de instâncias para cada estrato no conjunto de dados (treino e testes), do contrário pode ser que os nossos dados fiquem enviasados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m-V9cKC8MzN"
   },
   "outputs": [],
   "source": [
    "ratings[\"rating\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwYnXUa7TK0c"
   },
   "source": [
    "Pronto! Agora vamos fazer uma <font color='red'>amostragem estratificada</font> com base nas categorias da renda.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "przR0ZBZ8MzT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vi9Gp_QbTwFi"
   },
   "source": [
    "Acabamos de criar novos conjuntos de treino e de teste, que chamamos de <font color='red'>strat_train_set </font> e <font color='blue'>strat_test_set</font>.\n",
    "\n",
    " Estes conjuntos devem respeitar a estratificação que introduzimos baseada em \"median_income\" representado na nova variável categórica \"income_cat\".\n",
    "\n",
    " Vejamos se funcionou:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQb_sNWO8MzW"
   },
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set) #Proporção de cada categoria em strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9att4KJX-91"
   },
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts() / len(housing) #Proporção de cada categoria em housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHr7e4IUYc9K"
   },
   "source": [
    "Podemos agora comparar com a <font color='blue'> amostragem aleatória </font>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcQ8FM-u8Mzi"
   },
   "outputs": [],
   "source": [
    "#Função para calcular as proporções das categorias da característica \"income_cat\"\n",
    "def income_cat_proportions(data): \n",
    "    return data[\"income_cat\"].value_counts() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVQi0BkJZi6U"
   },
   "source": [
    "Agora vamos gerar novamente conjunto de teste e treino, mas usando amostragem aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0jyVWH8ZiBM"
   },
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AD0M3hAwZx87"
   },
   "source": [
    "Vamos criar o nosso novo dataframe e visualizar os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-RIbMERZxOt"
   },
   "outputs": [],
   "source": [
    "compare_props = pd.DataFrame({\n",
    "    \"Geral\": income_cat_proportions(housing),\n",
    "    \"Estratificado\": income_cat_proportions(strat_test_set),\n",
    "    \"Aleatorio\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "\n",
    "compare_props[\"Aleatório %erro\"] = 100 * compare_props[\"Aleatorio\"] / compare_props[\"Geral\"] - 100\n",
    "compare_props[\"Estratificado %erro\"] = 100 * compare_props[\"Estratificado\"] / compare_props[\"Geral\"] - 100\n",
    "\n",
    "compare_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFX8Ha0pao_z"
   },
   "source": [
    "Contentes com os resultados, não podemos esquecer de <font color='red'>remover</font> o atributo \"income_cat\" dos conjuntos strat_train_set e strat_test_set. Na verdade, ele era apenas um intermediário, afinal de contas as informações dessa caracaterísticas já estão presentes em \"median_income\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbPa45jL8Mzq"
   },
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYST0JOP8Mzu"
   },
   "source": [
    "# Visualização da estrutura de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dws-HQeEc3h0"
   },
   "source": [
    "Vamos agora visualizar os nossos dados. Precisamos ter certeza que não vamos visualizar dados do conjunto de teste, para evitar enviesamento de conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGYSWxqk8Mzv"
   },
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy() #Importante criar uma cópia! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1YxuAEV8Mzz"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjTUHRQYdcME"
   },
   "source": [
    "Vamos melhorar a visualição usando o parâmetro <font color='red'>alpha</font>, observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6pNMSKy8Mz4"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnWgQnQ2dxJ4"
   },
   "source": [
    "Interessante! Agora fica mais evidente a concentração dos agrupamentos!\n",
    "\n",
    "De qualquer forma devemos voltar a nossa atenção ao objetivo: <font color = 'red'> preços do setor imobioliário. </font> \n",
    "\n",
    "No código a seguir o parâmetro \"s\" significa \"size\", tamanho em inglês. Escolhendo \"s\" como sendo a característica população, quanto maior o disco representa uma população maior.\n",
    "\n",
    "O parâmetro \"c\" significa \"color\", ou cor. Esse é na verdade o que queremos saber!\n",
    "\n",
    "O paramêtro colorbar = True indica que queremos visualizar a barra lateral informando as intensidades da cor, ou seja, do parêmetro \"c\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uo34qLzu8Mz8"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False) #sharex=false é só pra corrigir um bug de display https://github.com/pandas-dev/pandas/issues/10611\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjuu3hmPmO3I"
   },
   "source": [
    "A visulização dos dados indicam que regiões litorâneas tendem a possuir um valor mais alto. Talevz a densidade populacional também possa ser algo relevante.\n",
    "\n",
    "Vamos então investigar essas hipóteses através da correleção estatística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWwTwI_D8M0E"
   },
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr() #Matriz de correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R50hJi6Sm0Ix"
   },
   "outputs": [],
   "source": [
    "corr_matrix #vamos ver a estrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eN1XZaZk8M0H"
   },
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False) #Ordenar valores em sentido decrescente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FDo4wlMqRlr"
   },
   "source": [
    "É conveniente usar o scatter_matrix do pandas. Essa função plota cada característica em relação a outra. No nosso exemplo, teríamos 121 possibilidades.\n",
    "\n",
    "Vamos aproveitar e ver alguns [conceitos básicos de estatística](http://geam.paginas.ufsc.br/files/2020/02/Estatistica_Basica.pdf).\n",
    "\n",
    "Mas claro que não faremos isso e vamos então selecionar algumas que parecem ser mais significativas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LpwQAvB8M0L"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1Cug8hvrd6-"
   },
   "source": [
    "OBS: Na diagonal principal da plotagem anterior não temos atributo x atributo, mas sim o histograma da característica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HG0nvHx8r7Rs"
   },
   "source": [
    "Vimos antes, que a característica que tinha maior correleção com o valor mediano de casas em um bairro era o salário mediano. Então vamos plotar para estudar a relação entre ambos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7tUBQjz8M0R"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1)\n",
    "plt.axis([0, 16, 0, 550000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AV671R0AscxC"
   },
   "source": [
    "Informações desta plotagem: \n",
    "\n",
    "1) Correlação é forte;\n",
    "\n",
    "2) Há um valor limiar de 500.000 para os valores (medianos) das casas. Por quê?\n",
    "\n",
    "3) Há também outras linhas horizontais. Por que elas são importantes?\n",
    "\n",
    "Uma abordagem possível seria excluir os dados correspondentes a esses casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwKPm7WPtR5y"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRpUMfun03Xe"
   },
   "source": [
    "Além das colunas que o conjunto de dados nos oferece, podemos tentar construir novas características <font color = \"red\">construídas de maneiras não linear</font> com as características existentes.\n",
    "\n",
    "De maneira geral, essa etapa requer conhecimento específico da área na qual se esta trabalhando. Daí a importância da presença de um especialista no assunto para auxiliar no projeto. \n",
    "\n",
    "A seguir, vamos construir algumas novas features que são mais ou menos lógicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owOuJWl-8M0Y"
   },
   "outputs": [],
   "source": [
    "#Nova feature: Número de cômodos por familia (média)\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "\n",
    "#Nova feature: quartos/cômodos\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "\n",
    "#Nova feature: população/agregado familiar\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPlzoY-D2Mo-"
   },
   "source": [
    "Vejamos agora a matriz de correlação de housing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIXxphSB8M0e"
   },
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1bPs-YC3Q5-"
   },
   "source": [
    "Aparentemente, casas com uma baixa proporção de quartos para cômodas tendem a ser mais caras. O número de cômodos por família é muito mais informartivo que o número total de quartos em um quarteirão.\n",
    "\n",
    "Vejamos o gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO40azQw8M0i"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
    "             alpha=0.2)\n",
    "plt.axis([0, 5, 0, 520000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVO_3R264SaH"
   },
   "source": [
    "Vamos ver novamente as medidas resumos considerando as novas features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-Je-Uao8M0n"
   },
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4K22d5b-8M0q"
   },
   "source": [
    "# Preparar os dados para os algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXXVeIOY7dcH"
   },
   "source": [
    "Precisamos incialmente retirar os rótulos do conjunto <fon color='blue'> strat_train_set </font> (mais a frente ficará claro).\n",
    "\n",
    "Para isso, vamos usar o método drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4f2vNh88M0r"
   },
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # O método drop cria cópia sem a coluna em questao\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() #salvando uma cópia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr8Yx1Gr8-D_"
   },
   "source": [
    "A partir de agora vamos partir para etapa de <font color='blue'>limpeza de dados!</font>\n",
    "\n",
    "Vamos começar verificandi se temos dados falantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OreIJJVV8M0v"
   },
   "outputs": [],
   "source": [
    "#housing.isnull().any(axis=1) verifica quais linhas possuem alguma célula null\n",
    "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g93mvTOr94j-"
   },
   "source": [
    "Possuímos basicamente três abordagens possíveis para lidar com os dados faltantes:\n",
    "\n",
    "1. Excluir os quarteirões com dados faltantes;\n",
    "\n",
    "2. Excluir toda coluna de total_bedrooms, já que é o único atributo que apresenta dados faltantes;\n",
    "\n",
    "3. Definir algum valor para substituir total_bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "am5Vp76w8M1A"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # opção 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zcb4CVvy8M1D"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # opção 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwK8qP9v-3ua"
   },
   "source": [
    "Opção 3: preenchendo com algum valor - nesse caso, usaremos a mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPjSOVok8M1H"
   },
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # opção 3\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7E8-2jaBMyu"
   },
   "source": [
    "Se escolhermos a opção 3, devemos calular a mediana (ou qualquer outra medida que seja justificável) no <font color=\"red\">conjunto de treinamento</font> e usá-lo para preencher os valores faltantes neste, mas precisamos <font color=\"blue\">salvar</font> esse valor cálculado.\n",
    "\n",
    "Você precisar desse valor para mais tarde aplicar no conjunto de teste, que deverá ter seus dados faltantes corrigidos seguindo o mesmo parâmetro do conjunto de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xpne_3kJBInq"
   },
   "source": [
    "**AVISO**: No Scikit-Learn 0.20, a classe `sklearn.preprocessing.Imputer` \n",
    "foi substituida pela classe `sklearn.impute.SimpleImputer`. Então, é conviniente verificar qual versão o computador em questão está usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Dy5nsFz8M1M"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
    "    print(\"Scikit-Learn 0.20+\")\n",
    "except ImportError:\n",
    "    from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "    print(\"Scikit-Learn antes do 0.20\")\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0iuZ4GFC2Wk"
   },
   "source": [
    "Vamos novamente revisar o nosso dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bC1UXCMtC7Dr"
   },
   "outputs": [],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_R3RrWmp8M1O"
   },
   "source": [
    "Ainda temos a última coluna que não é numérica! \n",
    "\n",
    "A princípios, grande parte dos algoritmos de machine learning no computador preferem os dados representados numericamente!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtSZSuXK8M1P"
   },
   "outputs": [],
   "source": [
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "# Derrubando a coluna \"ocean_proximity\"\n",
    "# alternativa: housing_num = housing.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oJNfnSNDrea"
   },
   "source": [
    "Agora vamos ajudar o nosso objeto imputer com o nossos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEXT2hQr8M1S"
   },
   "outputs": [],
   "source": [
    "imputer.fit(housing_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJ5SdBuUD27i"
   },
   "source": [
    "Aqui, o imputer simplesmente calculou a mediana no conjunto de dados.\n",
    "\n",
    "Vejamos algumas informações sobre o nosso objeto imputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sP3wAcyX8M1W"
   },
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0o1__l6p8M1a"
   },
   "source": [
    "Vamos verificar que isto é, na verdade, a mesma coisa que calcular manualmente a mediana de cada atributo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27Qi1YJc8M1c"
   },
   "outputs": [],
   "source": [
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8fmJCklEhzx"
   },
   "source": [
    "Mas não seria apenas o atributo \"total_bedrooms\" que estava com valores faltantes? \n",
    "\n",
    "Vamos precisar de todas as informações do imputer? Isto é, vamos precisar da mediana de todas as variáveis?\n",
    "\n",
    "<font color='red'> Não podemos, a princípio, afirmar que o mesmo padrão vai ser repetir na generalização do modelo! </font>\n",
    "\n",
    "Certo, mas e se dermos uma espiadinha no conjunto de testes?\n",
    "\n",
    "Não devemos fazer isso por vários motivos. \n",
    "\n",
    "1. Corremos o risco de colocar vieses no nosso modelo (assumir que apenas \"total_bedrooms\" terá colunas com dados faltantes em todos os cenários possíveis é um deles;\n",
    "\n",
    "2. Devemos ter sempre em mente que o conjunto de teste é no fundo uma simulação para testarmos o poder de generalização do algoritmo - devemos fazer todas as nossas análises e otimizações somente no conjunto de treinamento e então aplicar o modelo final uma única vez no conjunto de teste!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "df5gUu6H8M1j"
   },
   "source": [
    "Vamos agora finalmente <font color = 'blue'> transformar </font> o nosso conjunto de dados, aplicando, efetivamente, o valor calculado da mediana nos dados faltantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeMG56He8M1k"
   },
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num) #numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CWZP3rviHVT3"
   },
   "source": [
    "Vamos visualizar o conjunto X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzhW6FTsHYCA"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uM-cJ1LiHaS2"
   },
   "source": [
    "Se você se sentir mais confortável, pode transformar o conjunto X em um dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9CX4hOO8M1n"
   },
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, #importante informar nome das colunas\n",
    "                          index=housing.index) #DataFrame Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9szVFMcHhQa"
   },
   "source": [
    "Vejamos como é este dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mYCY8ltHlcD"
   },
   "outputs": [],
   "source": [
    "housing_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZ_0PzGe8M1y"
   },
   "source": [
    "Agora devemos tratar a variável categórica`ocean_proximity'!\n",
    "\n",
    "Lembre que esta é uma variável muito importante no nosso problema: ela demonstrava uma boa correlação com o preço mediano das casas.\n",
    "\n",
    "Vamos novamente visualizar os dados para relembrar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zZc51Ro8M1z"
   },
   "outputs": [],
   "source": [
    "housing_cat = housing[['ocean_proximity']]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHlDGSPp9drc"
   },
   "source": [
    "Agora vamos usar um processo chamado de codificação. Vamos transformar as nossas variáveis categóricas em números!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBeHjNq58M12"
   },
   "source": [
    "**OBS**: O código a seguir é apenas devido a atualização da classe OriginalEnconder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCgAnVEN8M13"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    print(\"Scikit-Learn >= 2.0\")\n",
    "except ImportError:\n",
    "    from future_encoders import OrdinalEncoder # Scikit-Learn < 0.20\n",
    "    print(\"O teu Scikit-Learn tá antiguinho mô quirido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jTIHNpV-YC0"
   },
   "source": [
    "Na função a seguir, precisamos instanciar um objeto ordinal_encoder. \n",
    "\n",
    "Depois, usamos fit_transform para executa duas operações:\n",
    "\n",
    "1. Método fit irá ajustar os parâmetros (mapeamento, por exemplo, quais são as variáveis categóricas); \n",
    "\n",
    "2. Método transform irá transformar os dados;\n",
    "\n",
    "3. fit_transform(dados) irá ajustar parâmetros e transformar os dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6IUvOsv8M15"
   },
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aAELI6TN_JMO"
   },
   "source": [
    "Uma alternativa mais prolixa teria sido escrever:\n",
    "\n",
    "original_encoder.fit(housing_cat)\n",
    "\n",
    "housing_cat_encoded = original_enconder.fit(housing_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35TkntyX_JgN"
   },
   "source": [
    "Vejamos que tipo de objeto é housing_cat_encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaHZCal8CNLd"
   },
   "outputs": [],
   "source": [
    "type(housing_cat_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GhaDm9TCQUd"
   },
   "source": [
    "Vamos ver agora os 10 primeiros valores desse numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZwZlPvV_J-B"
   },
   "outputs": [],
   "source": [
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71JIk01_CaPi"
   },
   "source": [
    "Vamos relembrar também as categorias do nosso problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGFUci_p8M18"
   },
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1uKeQbJ_IDx"
   },
   "source": [
    "Veja! \n",
    "\n",
    "O objeto ordinal_encoder foi construiído assim:\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() \n",
    "\n",
    "e depois fizemos o seguinte:\n",
    "\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "\n",
    "<font color = \"red\">Aqui não apenas definimos quem é \"housing_cat_encoded\" como também inserimos informações no objeto ordinal_encoder! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMDgx9IXDQp4"
   },
   "source": [
    "Apesar dos nossos esforços, temos um grave problema na nossa codificação, veja novamente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ej67X1XiGuVB"
   },
   "outputs": [],
   "source": [
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d9Wk1zfDYLy"
   },
   "outputs": [],
   "source": [
    "housing_cat[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxpbZPyhDaFA"
   },
   "source": [
    "Cada variável categórica foi transformada em número!\n",
    "\n",
    "Mas será que a princípio, podemos comparar uma variável categórica com outra?\n",
    "\n",
    "Quem é maior: NEAR OCEAN ou NEAR BAY? \n",
    "\n",
    "Bem, é difícil responder. Mas é isso que a nossa codificação implicítacamente está fazendo ao colocar os valores 0,1,2,3 ou 4 para cada variável categórica. \n",
    "\n",
    "<font color=\"red\"> Para lidar com essa situação precisamos então de outra abordagem!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRx3EyM_8M2A"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder # gera um ImportError se Scikit-Learn < 0.20\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "except ImportError:\n",
    "    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZmFwJfi8M2D"
   },
   "source": [
    "By default, the `OneHotEncoder` class returns a sparse array, but we can convert it to a dense array if needed by calling the `toarray()` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxZNJ3vdLhsy"
   },
   "source": [
    "Epa! Agora temos uma matriz SciPy ao invés de um Numpy array! \n",
    "\n",
    "<font color = \"red\">Por que será?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xj9Ui84j8M2F"
   },
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZrxw1P7LuGS"
   },
   "source": [
    "Temos agora uma matriz esparsa! (mais econômica computacionalmente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7Awc-A88M2H"
   },
   "source": [
    "Alternativamente, podemos colocar `sparse=False` ao criar o objeto `OneHotEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBpRUzXa8M2K"
   },
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffDhyjCS8M2Q"
   },
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBb4phIC8M2S"
   },
   "source": [
    "Let's create a custom transformer to add extra attributes:\n",
    "\n",
    "Vamos criar um transformador customizado para adicionar atributos extras \n",
    "\n",
    "**OBS**: aqui vamos simplesmente criar um código para o processo manual feito na etapa de Feature Engineering. Vai nos ajudar a criar um pipeline mais a frente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Elcx_lHE8M2T"
   },
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGcMGFu38M2X"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Buscando os indices corretos das colunas: \n",
    "# Mais seeguro que ficar digitando 3, 4, 5, 6..\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "    list(housing.columns).index(col)\n",
    "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Nada a fazer!\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9EO6KsJ8M2a"
   },
   "source": [
    "Alternativamente, você pode usar a função da classe `FunctionTransformer` que permite você criar rapidamente um transformador baseado em uma função de transformação! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rpc96Bz8M2b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def add_extra_features(X, add_bedrooms_per_room=True):\n",
    "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "    if add_bedrooms_per_room:\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "        return np.c_[X, rooms_per_household, population_per_household,\n",
    "                     bedrooms_per_room]\n",
    "    else:\n",
    "        return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = FunctionTransformer(add_extra_features, validate=False,\n",
    "                                 kw_args={\"add_bedrooms_per_room\": False})\n",
    "\n",
    "housing_extra_attribs = attr_adder.fit_transform(housing.values)\n",
    "\n",
    "#Vale a pena colocar validate=False já queos dados não possuem valores não-float\n",
    "#validate=false é valor padrão a partir do Scikit-Learn 0.22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7Kxr65r8M2d"
   },
   "outputs": [],
   "source": [
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
    "    index=housing.index)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQWec1HG8M2k"
   },
   "source": [
    "Agora vamos construir um \"pipeline\" (tradução literal: gasoduto) para pré-processar os atributos numéricos - obser que poderíamos usar <font color = 'blue'> CombinedAttributesAdder()</font>\n",
    "ao invés do <font color = 'blue'> FunctionTransformer(...) </font>, se quiséssemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQXJZ_Sj8M2l"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "#StandardScaler serve para fazer a reescalar das variáveis\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdcLN1nQ8M2p"
   },
   "outputs": [],
   "source": [
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqJnKiKU8M2s"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "except ImportError:\n",
    "    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeuhO_C28M2v"
   },
   "outputs": [],
   "source": [
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeMjEuO68M2x"
   },
   "outputs": [],
   "source": [
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdZ_g_4F8M22"
   },
   "outputs": [],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVtZVgtylH3S"
   },
   "source": [
    "Agora finalmente temos os nossos dados pré-processados! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEd0_zms8M3Q"
   },
   "source": [
    "# Selecionar e treinar um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNSjYgRslYpQ"
   },
   "source": [
    "Vamos começar com um modelo siples: Regressão Linear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tlfuq_N_8M3Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels) \n",
    "#Ei Regressão linear, encontre os parâmetros que melhor aproxima os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jftWY8qlw0V"
   },
   "source": [
    "Vamos agora testar o nosso pipeline de pré-processamento em algumas instâncias de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeIBOXrc8M3T"
   },
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data) \n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ee13jK88M3W"
   },
   "source": [
    "Vamos comparar agora com os valores reais:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKuAW3cF8M3W"
   },
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTiJNHzc8M3Z"
   },
   "outputs": [],
   "source": [
    "some_data_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFbq4GnVmDQe"
   },
   "source": [
    "Agora vamos usar as métricas que aprendemos anteriormente!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uM8zYtAz8M3c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = MSE(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse) #Não é necessariamente obrigatório\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVUWg9TX8M3e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "lin_mae = MAE(housing_labels, housing_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krWmzYCImYl3"
   },
   "source": [
    "Essse modelo ainda não parece ser adequado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j22oB0-98M3t"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJlEkoBQ8M3v"
   },
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = MSE(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLYetxKwmxhs"
   },
   "source": [
    "O quê? Erro zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f3xjl8BZonWR"
   },
   "source": [
    "#Vamos continuar na próxima aula a calibrar esse modelo!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6T9pPKu28Mwe",
    "UBjzryXYKMb5",
    "HMaugIFD5xmR",
    "QwKPm7WPtR5y",
    "4K22d5b-8M0q",
    "hEd0_zms8M3Q",
    "f3xjl8BZonWR"
   ],
   "name": "Aula 02.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
